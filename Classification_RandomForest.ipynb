{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, log_loss\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the negative and positive target?\n",
    "* One classifier for each class?\n",
    "* Should we use the nome_micro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying NotRequested/Susceptible Vs Resistant\n",
    "\n",
    "So in this aproach each row corresponds to a isolation request. Two classes are created: one for representing cases were no resistant to J01CA was detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nome_Micro',\n",
       " 'IDADE',\n",
       " 'Genero',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'Target_J01CA',\n",
       " 'Diagnosticos_new',\n",
       " 'Nome_Analises_new',\n",
       " 'Produto_Analises_new',\n",
       " 'Sintomas_new',\n",
       " 'nr_past_visits',\n",
       " 'nr_past_visits_7days',\n",
       " 'nr_past_visits_15days',\n",
       " 'nr_past_infections',\n",
       " 'nr_past_infections_7days',\n",
       " 'nr_past_infections_15days',\n",
       " 'fever_7days',\n",
       " 'fever_15days',\n",
       " 'cough_7days',\n",
       " 'cough_15days',\n",
       " 'diarrhea_7days',\n",
       " 'diarrhea_15days',\n",
       " 'fatigue_7days',\n",
       " 'fatigue_15days',\n",
       " 'J01CA_past_resistance',\n",
       " 'J01GB_past_resistance',\n",
       " 'J01DH_past_resistance',\n",
       " 'J01MA_past_resistance',\n",
       " 'J01DD_past_resistance',\n",
       " 'Past_Resistances',\n",
       " 'Hour',\n",
       " 'Weekday',\n",
       " 'Monthday',\n",
       " 'Month',\n",
       " 'Year',\n",
       " 'Temperature_3avg',\n",
       " 'Temperature_3std',\n",
       " 'Temperature_3min',\n",
       " 'Humidity_3avg',\n",
       " 'Humidity_3std',\n",
       " 'Humidity_3min',\n",
       " 'Temperature_5avg',\n",
       " 'Temperature_5std',\n",
       " 'Temperature_5min',\n",
       " 'Humidity_5avg',\n",
       " 'Humidity_5std',\n",
       " 'Humidity_5min',\n",
       " 'Temperature_7avg',\n",
       " 'Temperature_7std',\n",
       " 'Temperature_7min',\n",
       " 'Humidity_7avg',\n",
       " 'Humidity_7std',\n",
       " 'Humidity_7min']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data_loaded = pd.read_csv(\"data2classificy_j01ca_n2.csv\",sep=\";\")\n",
    "\n",
    "# Drop columns that must not be used\n",
    "columns2drop = ['ID_Isol','ID_Episodio','ID_Pedido','ID_Doente',\n",
    "                'Resistant_concat_Fam','Resistant_Anti','Infeccoes','Requested_Fam',\n",
    "                'DT_Admin','DT_Admin_temp','COLHEITA_DIFF','Dt_Colheita']\n",
    "data = data_loaded.drop(columns2drop,axis=1)\n",
    "\n",
    "# Check if there is missing data\n",
    "data.isnull().sum()[data.isnull().sum()>0]\n",
    "\n",
    "\n",
    "data.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that are a bunch of variables that seem to have quite a amount of missing data. Looking to these variables we can divide them in 3 groups:\n",
    "* Resistant_concat_Fam, Resistant_Anti, Diagnosticos_new, Nome_Analises_new, Produto_Analises_new, Sintomas_new, Infeccoes: When these variables are nan in fact means that missing is not random it means that no information was placed. The solution is just to replace these values by a value like 'Nenhum' to tell that no values were annotated by the clinical staff.\n",
    "* Latitude/Longitude: No information was provided to these features solution (replace by a specific value and creat another feature indicating if these variable is missing)\n",
    "* Weather features: These values are missing because we do not have data for the year 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Past_Resistances    16182\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing not at Random - empty values mean that a clinical observation was not written\n",
    "data['Diagnosticos_new'].fillna(\"Nenhum\",inplace=True)\n",
    "data['Produto_Analises_new'].fillna(\"Nenhum\",inplace=True)\n",
    "data['Nome_Analises_new'].fillna(\"Nenhum\",inplace=True)\n",
    "data['Sintomas_new'].fillna(\"Nenhum\",inplace=True)\n",
    "\n",
    "# Fill the nan values with the localization of one of the clinicals\n",
    "data['Longitude'].fillna(-9.1628837,inplace=True) \n",
    "data['Latitude'].fillna(38.748496,inplace=True)\n",
    "\n",
    "# There are 4 cases with \n",
    "data['Nome_Micro'].fillna(\"Nenhum\",inplace=True)\n",
    "\n",
    "# select variables of weather:\n",
    "weather_features = data.filter(regex='Temperature|Humidity').columns\n",
    "# Input values based on month and monthday\n",
    "for feat in weather_features:\n",
    "    data[feat] = data_loaded.groupby(['Month', 'Monthday'])[feat].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# Check if the nan imoutation was sucessfull\n",
    "data.isnull().sum()[data.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features concerning hour,day of the week, are not continous numeric but are not categorical either. They have ordered. If monday is coded as 0 and sunday as 6 we have to find a way to make this 0-6 (monday-sunday) be more close that for example 0-5(monday saturday). A way to data is to make this variabvles cyclic using a cos or sin function \n",
    "http://blog.davidkaleko.com/feature-engineering-cyclical-features.html\n",
    "\n",
    "One of the most common mistakes in data science is not properly dealing with cyclical features. Hours of the day, days of the week, months in a year, and wind direction are all examples of features that are cyclical. Many new machine learning engineers donâ€™t think to convert these features into a representation that can preserve information such as hour 23 and hour 0 being close to each other and not far. Yup. I've tried to predict my fair share of quantities using cyclical features incorrectly. Christopher points out that proper handling of such features involves representing the cyclical features as (x,y) coordinates on a circle. In this blog post, I'll explore this feature engineering task and see if it really improves the predictive capability of a simple model. Now the magic happens. We map each cyclical variable onto a circle such that the lowest value for that variable appears right next to the largest value. We compute the x- and y- component of that point using sin and cos trigonometric functions. You remember your unit circle, right? Here's what it looks like for the \"hours\" variable. Zero (midnight) is on the right, and the hours increase counterclockwise around the circle. In this way, 23:59 is very close to 00:00, as it should be. Note that when we perform this transformation for the \"month\" variable, we also shift the values down by one such that it extends from 0 to 11, for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform time variables cyclic with sin and cos fucntions\n",
    "data['hour_sin'] = np.sin(data_loaded['Hour']*(2.*np.pi/24))\n",
    "data['hour_cos'] = np.cos(data_loaded['Hour']*(2.*np.pi/24))\n",
    "data['month_sin'] = np.sin((data_loaded['Month']-1)*(2.*np.pi/12))\n",
    "data['month_cos'] = np.cos((data_loaded['Month']-1)*(2.*np.pi/12))\n",
    "data['weekday_sin'] = np.sin(data_loaded['Weekday']*(2.*np.pi/7))\n",
    "data['weekday_cos'] = np.cos(data_loaded['Weekday']*(2.*np.pi/7))\n",
    "data['monthday_sin'] = np.sin(data_loaded['Monthday']*(2.*np.pi/30))\n",
    "data['monthday_cos'] = np.cos(data_loaded['Monthday']*(2.*np.pi/30))\n",
    "\n",
    "#data.drop(['Hour','Month','Weekday','Monthday'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to dummerize the categorical variables becase other way random forest algorithm would be not capable of distinguish between integer and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosticos_new\n",
      " ... Removing dummies that appear less than 5 times: 361 removed.\n",
      "fatigue_15days\n",
      " ... Removing dummies that appear less than 5 times: 1 removed.\n",
      "Month\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "J01CA_past_resistance\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "cough_15days\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "Nome_Analises_new\n",
      " ... Removing dummies that appear less than 5 times: 310 removed.\n",
      "fatigue_7days\n",
      " ... Removing dummies that appear less than 5 times: 1 removed.\n",
      "fever_7days\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "Target_J01CA\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "Past_Resistances\n",
      " ... Removing dummies that appear less than 5 times: 1056 removed.\n",
      "Produto_Analises_new\n",
      " ... Removing dummies that appear less than 5 times: 27 removed.\n",
      "Hour\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "Weekday\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "cough_7days\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "diarrhea_7days\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "Sintomas_new\n",
      " ... Removing dummies that appear less than 5 times: 80 removed.\n",
      "diarrhea_15days\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "fever_15days\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "Genero\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "Year\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "J01MA_past_resistance\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "Nome_Micro\n",
      " ... Removing dummies that appear less than 5 times: 110 removed.\n",
      "J01GB_past_resistance\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "J01DD_past_resistance\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "Monthday\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n",
      "J01DH_past_resistance\n",
      " ... Removing dummies that appear less than 5 times: 0 removed.\n"
     ]
    }
   ],
   "source": [
    "def dumerize_bagofwords(dataset,feature,separator='--',drop_old=True):\n",
    "    dummies = dataset[feature].str.get_dummies(sep=separator)\n",
    "    for col_dummie_i in dummies.columns:\n",
    "        dummies = dummies.rename(columns = {col_dummie_i:str(feature)+ '_' + str(col_dummie_i)})\n",
    "        dummies = dummies.astype('uint8')\n",
    "    data = pd.concat([dataset,dummies],axis=1)\n",
    "    data = data.drop(feature,axis=1)\n",
    "    return data\n",
    "\n",
    "def dummerize_categorical(dataset,feature,drop_old=True):\n",
    "    dummies = pd.get_dummies(dataset[feature],drop_first=True,prefix=feature)\n",
    "    dummies = dummies.astype('uint8')\n",
    "    data = pd.concat([dataset,dummies],axis=1)\n",
    "    data = data.drop(feature,axis=1)\n",
    "    return data\n",
    "\n",
    "def remove_badfeatues(dataset,unique_thr=100):\n",
    "    print(\" ... Removing dummies that appear less than {} times:\".format(unique_thr),end=\" \")\n",
    "    # Copy dataset to avoid probels\n",
    "    dataset_out = dataset.copy()\n",
    "    # Select categorical variables\n",
    "    dataset_categorical = dataset_out.select_dtypes(include=['uint8'])\n",
    "    # List to store the names of features to keep\n",
    "    removidas = []\n",
    "    # Ltst to store the names of features to drop\n",
    "    mantidas = []\n",
    "    # Iterate thourgh the uint columns\n",
    "    for col in dataset_categorical.columns:\n",
    "        if dataset_categorical[col].sum() < unique_thr:\n",
    "            removidas.append(col)\n",
    "            dataset_out.drop([col],axis=1,inplace=True)\n",
    "        else:\n",
    "            mantidas.append(col)\n",
    "    # Print the number of columns to removed\n",
    "    print(\"{} removed.\".format(len(removidas)))\n",
    "    return dataset_out,removidas\n",
    "\n",
    "float_features = data.select_dtypes(include=['float64'])\n",
    "numerical_features = data.filter(regex='nr_|IDADE|Latitude|Longitude|Humidity|Temperature').columns.tolist()\n",
    "categorical_features = list(set(data.columns.tolist()) - set(numerical_features)-set(float_features))\n",
    "categorical_features\n",
    "\n",
    "data_new = data.copy()\n",
    "\n",
    "for feat_cat in categorical_features:\n",
    "    #if data_new[feat_cat].nunique()>2:\n",
    "        print(feat_cat)\n",
    "        if data_new[feat_cat].astype('object').str.contains('--').any():\n",
    "            data_new = dumerize_bagofwords(data_new,feat_cat,separator='--',drop_old=True)\n",
    "        else:\n",
    "            data_new = dummerize_categorical(data_new,feat_cat,drop_old=True)       \n",
    "        data_new,removidas = remove_badfeatues(data_new,unique_thr=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will separate the data and the targets and make a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_new['Target_J01CA_True']\n",
    "X = data_new.drop('Target_J01CA_True',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "col_list = []\n",
    "pvalue_list = []\n",
    "colunas  =  list(set(X.columns)-set(numerical_features)-set(float_features))\n",
    "for col in colunas:\n",
    "    #\"if col not in continous_vars:\n",
    "        #print(\"qui test for \", col)\n",
    "        observed = pd.crosstab(X[col],y, margins = False)\n",
    "\n",
    "        #print(observed)\n",
    "        chi2, p, dof, ex = stats.chi2_contingency(observed= observed,correction = True)\n",
    "        col_list.append(col)\n",
    "        pvalue_list.append(p)\n",
    "\n",
    "chi_test_pd = pd.DataFrame({'feature':col_list,'p_value':pvalue_list})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chi_test_pd.sort_values(by='p_value', ascending=True).head(10))\n",
    "print(chi_test_pd.sort_values(by='p_value', ascending=True).tail(10))\n",
    "#chi_test_pd.to_csv(\"data2classificy_j01ca_n_chi_test_pd_dummies.csv\",sep=\";\",encoding='utf-8',index=False)\n",
    "\n",
    "g = sns.factorplot(x=\"Nome_Analises_new_T4  LIVRE  (FT4)\", hue=\"Target_J01CA_True\",data=data_new, kind=\"count\",size=4, aspect=.7);\n",
    "plt.show()\n",
    "\n",
    "print(data_new[\"Nome_Analises_new_BIL   TOTAL \"].value_counts())\n",
    "print(data_new[\"Nome_Analises_new_GGT \"].value_counts())\n",
    "print(data_new[\"Produto_Analises_new_FEZES (MEIO DE TRANSPORTE)\"].value_counts())\n",
    "print(data_new[\"Nome_Analises_new_T4  LIVRE  (FT4)\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection = True\n",
    "if feature_selection:\n",
    "    ## This line instantiates the model. \n",
    "    rf = RandomForestClassifier(n_estimators=50) \n",
    "    ## Fit the model on your training data.\n",
    "    rf.fit(X_train, y_train) \n",
    "    ## And score it on your testing data.\n",
    "    rf.score(X_test, y_test)\n",
    "    # Build a dataframe with the feature importance sorted \n",
    "    feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                       index = X_train.columns,\n",
    "                                      columns=['importance']).sort_values('importance',ascending=False)\n",
    "    # Subset the best 1000 features\n",
    "    selected_features = feature_importances.index[0:1000]\n",
    "    X_train = X_train[selected_features]\n",
    "    X_test = X_test[selected_features]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model -  Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1,max_features='sqrt',n_estimators=10,oob_score=False)\n",
    "optimize_parameters = True\n",
    "\n",
    "if optimize_parameters:\n",
    "    # The scorers can be either be one of the predefined metric strings or a scorer\n",
    "    # callable, like the one returned by make_scorer\n",
    "    scoring = {'AUC': 'roc_auc','Accuracy':'accuracy'}\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators':[1,2,5,10,20,50,100],\n",
    "        'max_features':['auto','sqrt','log2',0.5,0.8]\n",
    "    }\n",
    "    \n",
    "    CV_rfc = GridSearchCV(estimator=rfc,param_grid=param_grid,cv=5,scoring=scoring,refit='Accuracy',return_train_score=True,verbose=2)\n",
    "    CV_rfc.fit(X_train,y_train)\n",
    "    \n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_search_traintime(cv_results,grid_param_1,grid_param_2,grid_param_3,name_param_1,name_param_2,name_param_3):\n",
    "    # Plot Grid search scores\n",
    "    _, ax = plt.subplots(2,2,figsize=(13,10))\n",
    "\n",
    "    \n",
    "     # Get Test Scores Mean and std for each grid search\n",
    "    scores_mean = cv_results['mean_test_AUC']\n",
    "    scores_mean = np.array(scores_mean).reshape(len(grid_param_2),len(grid_param_1))\n",
    "\n",
    "    scores_sd = cv_results['std_test_AUC']\n",
    "    scores_sd = np.array(scores_sd).reshape(len(grid_param_2),len(grid_param_1))\n",
    "\n",
    "\n",
    "    # Param1 is the X-axis, Param 2 is represented as a different curve (color line)\n",
    "    for idx, val in enumerate(grid_param_2):\n",
    "        ax[0,0].plot(grid_param_1, scores_mean[idx,:], ':o',markersize=4, label= name_param_2 + ': ' + str(val))\n",
    "\n",
    "    ax[0,0].set_title(\"Grid Search Scores\", fontsize=20, fontweight='bold')\n",
    "    ax[0,0].set_xlabel(name_param_1, fontsize=14)\n",
    "    ax[0,0].set_ylabel('CV Average AUC', fontsize=14)\n",
    "    ax[0,0].legend(loc=\"best\", fontsize=12)\n",
    "    ax[0,0].grid('on')\n",
    "    \n",
    "         # Get Test Scores Mean and std for each grid search\n",
    "    scores_mean = cv_results['mean_test_Accuracy']\n",
    "    scores_mean = np.array(scores_mean).reshape(len(grid_param_2),len(grid_param_1))\n",
    "\n",
    "    scores_sd = cv_results['std_test_Accuracy']\n",
    "    scores_sd = np.array(scores_sd).reshape(len(grid_param_2),len(grid_param_1))\n",
    "\n",
    "\n",
    "    # Param1 is the X-axis, Param 2 is represented as a different curve (color line)\n",
    "    for idx, val in enumerate(grid_param_2):\n",
    "        ax[0,1].plot(grid_param_1, scores_mean[idx,:], ':o',markersize=4, label= name_param_2 + ': ' + str(val))\n",
    "\n",
    "    ax[0,1].set_title(\"Grid Search Scores\", fontsize=20, fontweight='bold')\n",
    "    ax[0,1].set_xlabel(name_param_1, fontsize=14)\n",
    "    ax[0,1].set_ylabel('CV Average Accuracy', fontsize=14)\n",
    "    ax[0,1].legend(loc=\"best\", fontsize=12)\n",
    "    ax[0,1].grid('on')\n",
    "\n",
    "    \n",
    "         # Get Test Scores Mean and std for each grid search\n",
    "#     scores_mean = cv_results['mean_test_Accuracy']\n",
    "#     scores_mean = np.array(scores_mean).reshape(len(grid_param_3),len(grid_param_1))\n",
    "\n",
    "#     scores_sd = cv_results['std_test_Accuracy']\n",
    "#     scores_sd = np.array(scores_sd).reshape(len(grid_param_3),len(grid_param_1))\n",
    "\n",
    "\n",
    "#     # Param1 is the X-axis, Param 2 is represented as a different curve (color line)\n",
    "#     for idx, val in enumerate(grid_param_3):\n",
    "#         ax[1,0].plot(grid_param_1, scores_mean[idx,:], ':o',markersize=4, label= name_param_3 + ': ' + str(val))\n",
    "\n",
    "#     ax[1,0].set_title(\"Grid Search Scores\", fontsize=20, fontweight='bold')\n",
    "#     ax[1,0].set_xlabel(name_param_1, fontsize=14)\n",
    "#     ax[1,0].set_ylabel('CV Average Accuracy', fontsize=14)\n",
    "#     ax[1,0].legend(loc=\"best\", fontsize=12)\n",
    "#     ax[1,0].grid('on')\n",
    "    \n",
    "    \n",
    "    \n",
    "    time_mean = cv_results['mean_fit_time']\n",
    "    time_mean = np.array(time_mean).reshape(len(grid_param_2),len(grid_param_1))\n",
    "    \n",
    "    time_sd = cv_results['std_fit_time']\n",
    "    time_sd = np.array(time_sd).reshape(len(grid_param_2),len(grid_param_1))\n",
    "    \n",
    "    # Param1 is the X-axis, Param 2 is represented as a different curve (color line)\n",
    "    for idx, val in enumerate(grid_param_2):\n",
    "        ax[1,1].plot(grid_param_1, time_mean[idx,:], ':o',markersize=4, label= name_param_2 + ': ' + str(val))\n",
    "\n",
    "    ax[1,1].set_title(\"Grid Search Scores\", fontsize=20, fontweight='bold')\n",
    "    ax[1,1].set_xlabel(name_param_1, fontsize=14)\n",
    "    ax[1,1].set_ylabel('CV Average Train Time', fontsize=14)\n",
    "    ax[1,1].legend(loc=\"best\", fontsize=12)\n",
    "    ax[1,1].grid('on')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Calling Method\n",
    "plot_grid_search_traintime(CV_rfc.cv_results_, \n",
    "                           param_grid['n_estimators'], \n",
    "                           param_grid['max_features'], \n",
    "                           'N Estimators', \n",
    "                           'Max Features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized RF classifier\n",
    "rfc_optimized = RandomForestClassifier(n_estimators=500, max_features=0.8, min_samples_leaf = 1,n_jobs=-1)\n",
    "\n",
    "# Fit the model with training set\n",
    "rfc_optimized.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def build_roc_cnf(y_true,y_score,y_predicted):\n",
    "    fpr,tpr,thresholds = roc_curve(y_true,y_score[:,1])\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(fpr,tpr,color='darkorange',lw=2,label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0,1],[0,1],color='navy',lw=2,linestyle='--')\n",
    "    plt.xlim([-0.01,1.0])\n",
    "    plt.ylim([0.0,1.01])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    mat = confusion_matrix(y_true,y_predicted)\n",
    "    sns.heatmap(mat.T, square = True, annot=True, fmt='d', cmap = 'Blues')\n",
    "    plt.xlabel('true label')\n",
    "    plt.ylabel('predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_feature_importances(model, feature_names, autoscale=True, headroom=0.05, width=10, summarized_columns=None,topn=20,filename='feature_importance.png'):\n",
    "    \n",
    "    if autoscale:\n",
    "        x_scale = model.feature_importances_.max() + headroom\n",
    "    else:\n",
    "        x_scale = 1\n",
    "\n",
    "    feature_dict=dict(zip(feature_names, model.feature_importances_))\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    if summarized_columns:\n",
    "        for col_name in summarized_columns:\n",
    "            sum_value = sum(x for i, x in feature_dict.items() if col_name in i )\n",
    "            keys_to_remove = [i for i in feature_dict.keys() if col_name in i ]\n",
    "            for i in keys_to_remove:\n",
    "                feature_dict.pop(i)\n",
    "            feature_dict[col_name] = sum_value\n",
    "    results = pd.Series(feature_dict, index=feature_dict.keys())\n",
    "    results.sort_values(inplace=True)\n",
    "    results = results[-topn:]\n",
    "    results.plot(kind='barh', figsize=(width, len(results)/4), xlim=(0, x_scale))\n",
    "    plt.title(\"Feature Relative Importance\")\n",
    "    plt.tick_params(axis='both', labelsize=9)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #plt.savefig(filename)\n",
    "\n",
    "    \n",
    "# Predict on testing set\n",
    "y_predicted = rfc_optimized.predict(X_test)\n",
    "y_predicted_scores = rfc_optimized.predict_proba(X_test)\n",
    "target_names = ['J01CA Suscpetible/Not_Requested', 'J01CA Resistant']\n",
    "\n",
    "#print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_predicted))\n",
    "print(\"Classification report: \\n\", classification_report(y_test, y_predicted, target_names=target_names))\n",
    "print(\"Classification accuracy: \\n\", accuracy_score(y_test, y_predicted))\n",
    "print(\"Classification auc: \\n\", roc_auc_score(y_test, y_predicted_scores[:,1]))\n",
    "print(\"Classification logloss: \\n\", log_loss(y_test,y_predicted_scores[:,1]))\n",
    "\n",
    "build_roc_cnf(y_test,y_predicted_scores,y_predicted)\n",
    "\n",
    "w = pd.DataFrame({'target':y_test,'probs':y_predicted_scores[:,1]})\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.distplot(w.loc[w['target']==0,'probs'],bins=50,hist_kws={'range':(0,1),'rwidth':0.9, 'alpha':0.4},label=target_names[0])\n",
    "sns.distplot(w.loc[w['target']==1,'probs'],bins=50,hist_kws={'range':(0,1),'rwidth':0.9, 'alpha':0.4},label=target_names[1])\n",
    "plt.legend()\n",
    "plt.xlim([0,1])\n",
    "plt.show()\n",
    "\n",
    "plot_feature_importances(model = rfc_optimized,feature_names = X_train.columns)\n",
    "plt.show()\n",
    "\n",
    "plot_feature_importances(model = rfc_optimized,feature_names = X_train.columns,summarized_columns = categorical_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Suscpetible vs Resistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_loaded = pd.read_csv(\"data2classificy_j01ca_n.csv\",sep=\";\")\n",
    "\n",
    "# Subset rows to only pick rows where the j01ca class has been requested\n",
    "data_loaded = data_loaded.filter(items = ['Requested_Fam'],like='J01CA')\n",
    "\n",
    "# Drop columns that must not be used\n",
    "columns2drop = ['ID_Isol','ID_Episodio','ID_Pedido','ID_Doente',\n",
    "                'Resistant_concat_Fam','Resistant_Anti','Infeccoes',\n",
    "                'DT_Admin','COLHEITA_DIFF','Dt_Colheita']\n",
    "data = data_loaded.drop(columns2drop,axis=1)\n",
    "\n",
    "# Check if there is missing data\n",
    "data.isnull().sum()[data.isnull().sum()>0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
